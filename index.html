<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Neuromorphic Imaging with Density-based Spatiotemporal Denoising</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.jpg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Neuromorphic Imaging with Density-based Spatiotemporal Denoising
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">IEEE Transactions on Computational Imaging <br> May 2023</span>
              <br>
              <!-- Paper authors -->
              <span class="author-block"><a href="https://scholar.google.com/citations?hl=en&user=Haaxgp0AAAAJ"
                  target="_blank">Pei Zhang</a><sup>*</sup>,</span>
              <span class="author-block"><a href="https://scholar.google.com/citations?user=mR4sMzEAAAAJ&hl=en"
                  target="_blank">Zhou Ge</a><sup>*</sup>,</span>
              <span class="author-block"><a href="https://orcid.org/0000-0002-3677-4329" target="_blank">Li
                  Song</a><sup>*</sup>,</span>
              <span class="author-block"><a href="https://www.eee.hku.hk/~elam/index.html" target="_blank">Edmund Y.
                  Lam</a><sup>*</sup><sup>&#9768</sup>,</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="eql-cntrb"><small><sup>*</sup>Department of Electrical and Electronic Engineering, The
                  University of Hong Kong, Pokfulam, Hong Kong SAR, China.</small></span>
              <span class="eql-cntrb"><small><br><sup>&#9768</sup>AI Chip Center for Emerging Smart Systems, Hong Kong
                  Science Park, Hong Kong SAR, China.</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://ieeexplore.ieee.org/document/10138453" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://connecthkuhk-my.sharepoint.com/:u:/g/personal/u3008016_connect_hku_hk/EU1CVbq4zE5Jozh1YR7ZHNUBCda2jrnI4256rpyHm1Y3gA" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>Data Samples</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!== Your video here ==>
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">OVERVIEW</h2><br>
          <img src="static/images/video.gif" alt="MY ALT TEXT" width="1000" height="800" />
          <br><br>
          <div class="content has-text-justified">
            <p>
              Neuromorphic cameras asynchronously record visual information of dynamic scenes by discrete
              events. They are also susceptible to interference and can generate a
              lot of noise in response. Such noisy event data can dramatically degrade the event-based observations and analysis.
              We propose a simple yet effective clustering algorithm with event-oriented approximation strategies for neuromorphic noise removal in a sub-quadratic fashion.
              It couples event priors with spatiotemporal density estimation, where strongly correlated signals are taken to be denser in space-time.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- <section class="hero is-small methodcolor">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
          <h2 class="title is-3">METHODOLOGY</h2><br>
          <img src="static/images/method.png" alt="MY ALT TEXT" width="800" height="800" />
          <br><br>
          <div class="content has-text-justified">
            <p>
              We propose a simple yet effective clustering algorithm for raw event denoising,
              which bridges event priors and spatiotemporal density analysis. Such a density-based mechanism, consistent with human observation, 
              is both rational and interpretable. We first couple a classic clustering (Algorithm 1 & 2) with asynchronous and sparse events, 
              and investigate the feasibility of space-time event density to discriminate between signals and noise. 
              Then, by leveraging the features of neuromorphic data, we design event-oriented strategies (Algorithm 3 & 4) to approximate the clustering, 
              which can effectively improve denoising performance with reduced computing resources.
            </p>
          </div>
        </div>
      </div>
      </div>
    </div>
  </section> -->


  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop is-centered has-text-centered">
        <h2 class="title is-3">DEMO</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <p class="subtitle">
              Denoising performance on the challenging scene.<br>
              We use a blue box to mark the zone with the signals and a red box for the
              one with the noise.<br>
              Our algorithm is more effective in discriminating between signals and noise, retaining most details while clearing noise.
            </p>
            <img src="static/images/results1.png" alt="MY ALT TEXT" />
          </div>
          <div class="item">
            <!-- Your image here -->
            <p class="subtitle">
              We examine the denoising ability when the objects are recorded by fast-moving and
              slow-moving cameras. <br>Signals generated by the latter normally have a longer time interval similar to that of noise.<br>
              The comparison shows the robustness of our algorithm to such challenging cases.
            </p>
            <img src="static/images/results2.png" alt="MY ALT TEXT" />
          </div>
          <div class="item">
            <!-- Your image here -->
            <p class="subtitle">
              Effective denoising boosts classification accuracy on event data.<br>
              We compare top-1 classification accuracy on the denoised events processed by each algorithm. <br>
              Our denoised events achieve better improvements than other counterparts.
            </p>
            <img src="static/images/results3.png" alt="MY ALT TEXT" />
          </div>
          <div class="item">
            <!-- Your image here -->
            <p class="subtitle">
              We use &#951 as another independent evaluation.<br> The comparisons present higher values of &#951 with our
              method for most test cases.
            </p>
            <img src="static/images/results4.png" alt="MY ALT TEXT" />
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->




  <!-- Youtube video -->
  <!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!== Paper video. ==>
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!== Youtube embed code here ==>
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
  <!-- End youtube video -->


  <!-- Video carousel
  <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!== Your video file here ==>
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
  End video carousel -->






  <!-- Paper poster -->
  <!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{zhang2023neuro,
          title   = {Neuromorphic Imaging With Density-Based Spatiotemporal Denoising},
          author  = {Zhang, Pei and Ge, Zhou and Song, Li and Lam, Edmund Y.},
          journal = {IEEE Transactions on Computational Imaging}, 
          volume  = {9}
          pages   = {530--541},
          month   = {May},
          year    = {2023},
          doi     = {10.1109/TCI.2023.3281202}
        }
      </code></pre>
      <b>Find more Neuromorphic Imaging projects from our group:</b> <br><br>
      <small>&#x2022 Zhou Ge, Haoyu Wei, Feng Xu, Yizhao Gao, Zhiqin Chu, Hayden K.-H. So, and Edmund Y. Lam, 
      “<a href="https://www.sciencedirect.com/science/article/abs/pii/S0143816622003001?via%3Dihub"
      target="_blank">Millisecond autofocusing microscopy using neuromorphic event sensing</a>,” 
      Optics and Lasers in Engineering, vol. 160, pp. 107247(1–9), January 2023.</small><br>

      <small>&#x2022 Zhou Ge, Pei Zhang, Yizhao Gao, Hayden K.-H. So, and Edmund Y. Lam, “<a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-30-2-2206&id=467925"
      target="_blank">Lens-free motion analysis via neuromorphic laser speckle imaging</a>,” Optics Express, vol. 30, no. 2, pp. 2206–2218, January 2022.</small><br>

      <small>&#x2022 Zhou Ge, Yizhao Gao, Hayden K.-H. So, and Edmund Y. Lam, 
      “<a href="https://opg.optica.org/ol/abstract.cfm?uri=ol-46-16-3885"
      target="_blank">Event-based laser speckle correlation for micro motion estimation</a>,” 
      Optics Letters, vol. 46, no. 16, pp. 3885–3888, August 2021.</small>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content footersize">
            <p>
              This page is based on the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a>.
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->
<!-- Default Statcounter code for NeuroDenoising
https://discriminative.github.io/NeuroDenoising/ -->
<script type="text/javascript">
var sc_project=12887119; 
var sc_invisible=1; 
var sc_security="3019cd47"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img class="statcounter"
src="https://c.statcounter.com/12887119/0/3019cd47/1/" alt="Web Analytics"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->
  <!-- End of Statcounter Code -->

  

</body>

</html>